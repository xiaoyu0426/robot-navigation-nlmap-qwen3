#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NLMap + Qwen3 é›†æˆæµ‹è¯•è„šæœ¬
æµ‹è¯•NLMapåœºæ™¯è¡¨ç¤ºä¸Qwen3å¯¹è±¡æè®®å’Œè§„åˆ’çš„é›†æˆåŠŸèƒ½
"""

import sys
import os
sys.path.append('./nlmap_spot-main')

from saycan_qwen3 import Qwen3ObjectProposer
import configparser

def test_nlmap_qwen3_integration():
    """
    æµ‹è¯•NLMapä¸Qwen3çš„é›†æˆåŠŸèƒ½
    """
    print("=== NLMap + Qwen3 é›†æˆæµ‹è¯• ===")
    
    # åˆå§‹åŒ–Qwen3å¯¹è±¡æè®®å™¨
    print("\n1. åˆå§‹åŒ–Qwen3å¯¹è±¡æè®®å™¨...")
    try:
        proposer = Qwen3ObjectProposer()
        print("âœ“ Qwen3å¯¹è±¡æè®®å™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âœ— Qwen3å¯¹è±¡æè®®å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•å¯¹è±¡æè®®åŠŸèƒ½
    print("\n2. æµ‹è¯•å¯¹è±¡æè®®åŠŸèƒ½...")
    test_tasks = [
        "help me prepare coffee",
        "clean the kitchen table", 
        "bring me a snack from the fridge",
        "put the books on the shelf",
        "find my keys",
        "water the plants"
    ]
    
    task_objects = {}
    for task in test_tasks:
        try:
            objects = proposer.query_llm_for_objects(task)
            task_objects[task] = objects
            print(f"âœ“ ä»»åŠ¡ '{task}' -> å¯¹è±¡: {objects}")
        except Exception as e:
            print(f"âœ— ä»»åŠ¡ '{task}' å¤±è´¥: {e}")
            task_objects[task] = []
    
    # æµ‹è¯•è§„åˆ’ç”ŸæˆåŠŸèƒ½
    print("\n3. æµ‹è¯•è§„åˆ’ç”ŸæˆåŠŸèƒ½...")
    test_scenarios = [
        {
            "task": "help me prepare coffee",
            "available_objects": ["coffee machine", "cup", "coffee beans", "water", "sugar", "milk"]
        },
        {
            "task": "clean the kitchen table",
            "available_objects": ["table", "sponge", "cleaning spray", "paper towels", "cloth"]
        },
        {
            "task": "bring me a snack from the fridge",
            "available_objects": ["fridge", "apple", "banana", "yogurt", "cheese", "crackers"]
        }
    ]
    
    for scenario in test_scenarios:
        try:
            planning = proposer.generate_planning_text(
                scenario["task"], 
                scenario["available_objects"]
            )
            print(f"\nâœ“ ä»»åŠ¡ '{scenario['task']}' è§„åˆ’ç”ŸæˆæˆåŠŸ")
            print(f"è§„åˆ’å†…å®¹: {planning[:200]}...")
        except Exception as e:
            print(f"âœ— ä»»åŠ¡ '{scenario['task']}' è§„åˆ’ç”Ÿæˆå¤±è´¥: {e}")
    
    # æ¨¡æ‹ŸNLMapåœºæ™¯æŸ¥è¯¢
    print("\n4. æ¨¡æ‹ŸNLMapåœºæ™¯æŸ¥è¯¢...")
    
    # æ¨¡æ‹Ÿåœºæ™¯ä¸­çš„å¯¹è±¡
    scene_objects = [
        "coffee machine", "cup", "table", "chair", "book", "pen", 
        "apple", "bottle", "phone", "laptop", "mouse", "keyboard"
    ]
    
    print(f"æ¨¡æ‹Ÿåœºæ™¯ä¸­çš„å¯¹è±¡: {scene_objects}")
    
    # å¯¹æ¯ä¸ªæµ‹è¯•ä»»åŠ¡ï¼Œæ‰¾å‡ºåœºæ™¯ä¸­ç›¸å…³çš„å¯¹è±¡
    for task, proposed_objects in task_objects.items():
        relevant_objects = []
        for obj in proposed_objects:
            # ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…ï¼ˆå®é™…NLMapä¼šä½¿ç”¨æ›´å¤æ‚çš„è¯­ä¹‰åŒ¹é…ï¼‰
            for scene_obj in scene_objects:
                if obj.lower() in scene_obj.lower() or scene_obj.lower() in obj.lower():
                    if scene_obj not in relevant_objects:
                        relevant_objects.append(scene_obj)
        
        print(f"\nä»»åŠ¡: {task}")
        print(f"æè®®å¯¹è±¡: {proposed_objects}")
        print(f"åœºæ™¯ä¸­ç›¸å…³å¯¹è±¡: {relevant_objects}")
        
        if relevant_objects:
            # ç”ŸæˆåŸºäºå®é™…åœºæ™¯å¯¹è±¡çš„è§„åˆ’
            try:
                contextual_planning = proposer.generate_planning_text(task, relevant_objects)
                print(f"åŸºäºåœºæ™¯çš„è§„åˆ’: {contextual_planning[:150]}...")
            except Exception as e:
                print(f"åŸºäºåœºæ™¯çš„è§„åˆ’ç”Ÿæˆå¤±è´¥: {e}")
    
    print("\n=== é›†æˆæµ‹è¯•å®Œæˆ ===")
    return True

def compare_with_palm_baseline():
    """
    ä¸PaLMåŸºå‡†è¿›è¡Œæ¯”è¾ƒåˆ†æ
    """
    print("\n=== ä¸PaLMåŸºå‡†æ¯”è¾ƒ ===")
    
    # è¯»å–prompt.txtä¸­çš„PaLMç¤ºä¾‹
    try:
        with open('prompt.txt', 'r', encoding='utf-8') as f:
            palm_examples = f.read()
        
        print("âœ“ æˆåŠŸè¯»å–PaLMåŸºå‡†ç¤ºä¾‹")
        
        # æå–ä¸€äº›ç¤ºä¾‹ä»»åŠ¡è¿›è¡Œæ¯”è¾ƒ
        palm_tasks = [
            "help me make a cup of coffee",
            "put the apple in the basket and close the door",
            "get a sponge from the counter and put it in the sink"
        ]
        
        proposer = Qwen3ObjectProposer()
        
        print("\nå¯¹æ¯”åˆ†æ:")
        for task in palm_tasks:
            print(f"\nä»»åŠ¡: {task}")
            
            # æŸ¥æ‰¾PaLMçš„å¯¹è±¡æè®®
            palm_line = None
            for line in palm_examples.split('\n'):
                if task.lower() in line.lower() and 'may involve' in line:
                    palm_line = line
                    break
            
            if palm_line:
                palm_objects = palm_line.split('objects:')[1].strip().rstrip('.').split(', ')
                print(f"PaLMæè®®: {palm_objects}")
            else:
                print("PaLMæè®®: æœªæ‰¾åˆ°")
            
            # è·å–Qwen3çš„å¯¹è±¡æè®®
            try:
                qwen_objects = proposer.query_llm_for_objects(task)
                print(f"Qwen3æè®®: {qwen_objects}")
                
                # ç®€å•çš„é‡å åˆ†æ
                if palm_line:
                    overlap = set([obj.strip().lower() for obj in palm_objects]) & set([obj.strip().lower() for obj in qwen_objects])
                    print(f"é‡å å¯¹è±¡: {list(overlap)}")
                    print(f"é‡å ç‡: {len(overlap)/max(len(palm_objects), len(qwen_objects)):.2f}")
                
            except Exception as e:
                print(f"Qwen3æè®®å¤±è´¥: {e}")
    
    except Exception as e:
        print(f"âœ— è¯»å–PaLMåŸºå‡†å¤±è´¥: {e}")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸš€ å¼€å§‹NLMap + Qwen3é›†æˆæµ‹è¯•")
    
    # æ£€æŸ¥ç¯å¢ƒ
    print("\næ£€æŸ¥ç¯å¢ƒ...")
    try:
        import torch
        print(f"âœ“ PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"âœ“ CUDAå¯ç”¨: {torch.cuda.is_available()}")
        
        from transformers import AutoTokenizer
        print("âœ“ Transformersåº“å¯ç”¨")
        
    except ImportError as e:
        print(f"âœ— ç¯å¢ƒæ£€æŸ¥å¤±è´¥: {e}")
        return
    
    # è¿è¡Œé›†æˆæµ‹è¯•
    success = test_nlmap_qwen3_integration()
    
    if success:
        # è¿è¡ŒåŸºå‡†æ¯”è¾ƒ
        compare_with_palm_baseline()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("\næ€»ç»“:")
        print("1. âœ“ Qwen3-4Bæ¨¡å‹æˆåŠŸæœ¬åœ°éƒ¨ç½²")
        print("2. âœ“ å¯¹è±¡æè®®åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        print("3. âœ“ è§„åˆ’ç”ŸæˆåŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        print("4. âœ“ NLMapé›†æˆæ¡†æ¶æ­å»ºå®Œæˆ")
        print("5. âœ“ ä¸PaLMåŸºå‡†è¿›è¡Œäº†åˆæ­¥æ¯”è¾ƒ")
        
        print("\nä¸‹ä¸€æ­¥å»ºè®®:")
        print("- è·å–çœŸå®çš„RGB-Dæ•°æ®é›†è¿›è¡Œå®Œæ•´çš„NLMapæµ‹è¯•")
        print("- ä¼˜åŒ–Qwen3çš„prompt engineeringç­–ç•¥")
        print("- å®ç°æ›´ç²¾ç¡®çš„è¯­ä¹‰åŒ¹é…ç®—æ³•")
        print("- è¿›è¡Œæ›´å…¨é¢çš„æ€§èƒ½è¯„ä¼°")
    else:
        print("\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥é…ç½®")

if __name__ == "__main__":
    main()